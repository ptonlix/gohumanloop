<div align="center">

![Wordmark Logo of HumanLayer](./docs/images/wordmark.png)
<b face="é›…é»‘">Perfecting AI workflows with human intelligence</b>

</div>

**GoHumanLoop**: A Python library empowering AI agents to dynamically request human input (approval/feedback/conversation) at critical stages. Core features:

- `Human-in-the-loop control`: Lets AI agent systems pause and escalate decisions, enhancing safety and trust.
- `Multi-channel integration`: Supports Terminal, Email, API, and frameworks like LangGraph/CrewAI (soon).
- `Flexible workflows`: Combines automated reasoning with human oversight for reliable AI operations.

Ensures responsible AI deployment by bridging autonomous agents and human judgment.

<div align="center">
<img alt="Repostart" src="https://img.shields.io/github/stars/ptonlix/gohumanloop"/>
<img alt=" Python" src="https://img.shields.io/badge/Python-3.10%2B-blue"/>
<img alt="license" src="https://img.shields.io/badge/license-MIT-green"/>

[ç®€ä½“ä¸­æ–‡](README-zh.md) | English

</div>

## Table of contents

- [Getting Started](#getting-started)
- [Why GoHumanloop?](#why-humanlayer)
- [Key Features](#key-features)
- [Roadmap](#roadmap)
- [Contributing](#contributing)
- [License](#license)

## ğŸ¹ Getting Started

å¿«é€Ÿå¼€å§‹ï¼Œè¯·æŸ¥çœ‹ä»¥ä¸‹ç¤ºä¾‹æˆ–ç›´æ¥è·³è½¬åˆ°[ç¤ºä¾‹ä»“åº“](https://github.com/ptonlix/gohumanloop-examples)ä¸­çš„æ¡ˆä¾‹ï¼š

- ğŸ¦œâ›“ï¸ [LangGraph](https://github.com/ptonlix/gohumanloop-examples/tree/main/LangGraph)
- ğŸš£â€ [CrewAI](https://github.com/ptonlix/gohumanloop-examples/tree/main/CrewAI)

### Installation

**GoHumanLoop** ç›®å‰æ”¯æŒ`Python`

- å®‰è£…

```shell
pip install gohumanloop
```

### Example

ä»¥ä¸‹åŸºäº [LangGraph å®˜æ–¹ä¾‹å­](https://langchain-ai.github.io/langgraph/tutorials/get-started/4-human-in-the-loop/#5-resume-execution) é€šè¿‡ `GoHumanLoop`å‡çº§ `human-in-the-loop`

> ğŸ’¡ é»˜è®¤é‡‡ç”¨ `Terminal` ä½œä¸º `langgraph_adapter` äººæœºäº¤äº’æ–¹å¼

```python
import os
from langchain.chat_models import init_chat_model
from typing import Annotated

from langchain_tavily import TavilySearch
from langchain_core.tools import tool
from typing_extensions import TypedDict

from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode, tools_condition

# from langgraph.types import Command, interrupt  # Don't use langgraph, use gohumanloop instead

from gohumanloop.adapters.langgraph_adapter import interrupt, create_resume_command

# Please replace with your Deepseek API Key from https://platform.deepseek.com/usage
os.environ["DEEPSEEK_API_KEY"] = "sk-xxx"
# Please replace with your Tavily API Key from https://app.tavily.com/home
os.environ["TAVILY_API_KEY"] = "tvly-xxx"

llm = init_chat_model("deepseek:deepseek-chat")

class State(TypedDict):
    messages: Annotated[list, add_messages]

graph_builder = StateGraph(State)

@tool
def human_assistance(query: str) -> str:
    """Request assistance from a human."""
    human_response = interrupt({"query": query})
    return human_response

tool = TavilySearch(max_results=2)
tools = [tool, human_assistance]
llm_with_tools = llm.bind_tools(tools)

def chatbot(state: State):
    message = llm_with_tools.invoke(state["messages"])
    # Because we will be interrupting during tool execution,
    # we disable parallel tool calling to avoid repeating any
    # tool invocations when we resume.
    assert len(message.tool_calls) <= 1
    return {"messages": [message]}

graph_builder.add_node("chatbot", chatbot)

tool_node = ToolNode(tools=tools)
graph_builder.add_node("tools", tool_node)

graph_builder.add_conditional_edges(
    "chatbot",
    tools_condition,
)
graph_builder.add_edge("tools", "chatbot")
graph_builder.add_edge(START, "chatbot")

memory = MemorySaver()

graph = graph_builder.compile(checkpointer=memory)

user_input = "I need some expert guidance for building an AI agent. Could you request assistance for me?"
config = {"configurable": {"thread_id": "1"}}

events = graph.stream(
    {"messages": [{"role": "user", "content": user_input}]},
    config,
    stream_mode="values",
)
for event in events:
    if "messages" in event:
        event["messages"][-1].pretty_print()

# LangGraph code:
# human_response = (
#     "We, the experts are here to help! We'd recommend you check out LangGraph to build your agent."
#     "It's much more reliable and extensible than simple autonomous agents."
# )

# human_command = Command(resume={"data": human_response})

# GoHumanLoop code:
human_command = create_resume_command() # Use this command to resume the executionï¼Œinstead of using the command above

events = graph.stream(human_command, config, stream_mode="values")
for event in events:
    if "messages" in event:
        event["messages"][-1].pretty_print()

```

- éƒ¨ç½²æµ‹è¯•

è¿è¡Œä¸Šè¿°ä»£ç 

```shell
# 1.Initialize environment
uv init gohumanloop-example
cd gohumanloop-example
uv venv .venv --python=3.10

# 2.Copy the above code to main.py

# 3.Deploy and test
uv pip install langchain
uv pip install langchain_tavily
uv pip install langgraph
uv pip install langchain-deepseek
uv pip install gohumanloop

python main.py

```

- äº¤äº’ä¿¡æ¯

![ç»ˆç«¯å±•ç¤º](http://cdn.oyster-iot.cloud/202505232244870.png)

è¿›è¡Œ `human-in-the-loop` äº¤äº’, è¾“å…¥ä¿¡æ¯

> We, the experts are here to help! We'd recommend you check out LangGraph to build your agent.It's much more reliable and extensible than simple autonomous agents.

![è¾“å‡ºç»“æœ](http://cdn.oyster-iot.cloud/202505232248390.png)

å®Œæˆ ğŸš€ğŸš€ğŸš€

â¡ï¸ æ›´å¤šç¤ºä¾‹è¯·æŸ¥çœ‹[ç¤ºä¾‹ä»“åº“](https://github.com/ptonlix/gohumanloop-examples)ï¼Œå¹¶æœŸå¾…ä½ çš„åˆ†äº«ï½

## ğŸµ Why GoHumanloop?

### Human-in-the-loop

<div align="center">
	<img height=240 src="http://cdn.oyster-iot.cloud/202505210851404.png"><br>
    <b face="é›…é»‘">Even with state-of-the-art agentic reasoning and prompt routing, LLMs are not sufficiently reliable to be given access to high-stakes functions without human oversight</b>
</div>
<br>

`Human-in-the-loop` æ˜¯ä¸€ç§ AI ç³»ç»Ÿè®¾è®¡ç†å¿µï¼Œå®ƒå°†äººç±»åˆ¤æ–­å’Œç›‘ç£æ•´åˆåˆ° AI å†³ç­–è¿‡ç¨‹ä¸­ã€‚åœ¨ AI Agent ç³»ç»Ÿä¸­ï¼Œè¿™ä¸€æ¦‚å¿µå°¤ä¸ºé‡è¦ï¼š

- **å®‰å…¨æ€§ä¿éšœ**: å…è®¸äººç±»åœ¨å…³é”®å†³ç­–ç‚¹è¿›è¡Œå¹²é¢„å’Œå®¡æ ¸ï¼Œé˜²æ­¢ AI åšå‡ºæ½œåœ¨æœ‰å®³çš„å†³ç­–
- **è´¨é‡æ§åˆ¶**: é€šè¿‡äººç±»ä¸“å®¶çš„åé¦ˆæ¥æå‡ AI è¾“å‡ºçš„å‡†ç¡®æ€§å’Œå¯é æ€§
- **æŒç»­å­¦ä¹ **: AI ç³»ç»Ÿå¯ä»¥ä»äººç±»åé¦ˆä¸­å­¦ä¹ å’Œæ”¹è¿›ï¼Œå½¢æˆè‰¯æ€§å¾ªç¯
- **è´£ä»»æ˜ç¡®**: åœ¨é‡è¦å†³ç­–ä¸Šä¿æŒäººç±»çš„æœ€ç»ˆæ§åˆ¶æƒï¼Œæ˜ç¡®å†³ç­–è´£ä»»

åœ¨å®é™…åº”ç”¨ä¸­ï¼ŒHuman-in-the-loop å¯ä»¥æ˜¯å¤šç§å½¢å¼ï¼šä»ç®€å•çš„å†³ç­–ç¡®è®¤åˆ°æ·±åº¦çš„äººæœºåä½œå¯¹è¯ï¼Œç¡®ä¿ AI ç³»ç»Ÿåœ¨è‡ªä¸»æ€§å’Œäººç±»ç›‘ç£ä¹‹é—´è¾¾åˆ°æœ€ä½³å¹³è¡¡ï¼Œå‘æŒ¥å‡º AI Agent ç³»ç»Ÿçš„æœ€å¤§æ½œåŠ›ã€‚

#### å…¸å‹åº”ç”¨åœºæ™¯

<div align="center">
	<img height=120 src="http://cdn.oyster-iot.cloud/tool-call-review.png"><br>
    <b face="é›…é»‘"> A human can review and edit the output from the agent before proceeding. This is particularly critical in applications where the tool calls requested may be sensitive or require human oversight.</b>
</div>
<br>

- ğŸ› ï¸ å®¡æ ¸å·¥å…·è°ƒç”¨ï¼šåœ¨å·¥å…·æ‰§è¡Œå‰ï¼Œäººå·¥å¯å®¡æ ¸ã€ç¼–è¾‘æˆ–æ‰¹å‡†ç”±å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å‘èµ·çš„å·¥å…·è°ƒç”¨è¯·æ±‚ã€‚
- âœ… éªŒè¯æ¨¡å‹è¾“å‡ºï¼šäººå·¥å¯å®¡æ ¸ã€ç¼–è¾‘æˆ–æ‰¹å‡†å¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆçš„å†…å®¹ï¼ˆå¦‚æ–‡æœ¬ã€å†³ç­–ç­‰ï¼‰ã€‚
- ğŸ’¡ æä¾›ä¸Šä¸‹æ–‡ï¼šå…è®¸å¤§è¯­è¨€æ¨¡å‹ä¸»åŠ¨è¯·æ±‚äººå·¥è¾“å…¥ï¼Œä»¥è·å–æ¾„æ¸…ã€è¡¥å……ç»†èŠ‚æˆ–æ”¯æŒå¤šè½®å¯¹è¯çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚

### å®‰å…¨é«˜æ•ˆ Goâ¡Humanloop

`GoHumanloop`æä¾›äº†ä¸€å¥—å·¥å…·æ·±åº¦é›†æˆåœ¨ AI Agent å†…éƒ¨ï¼Œç¡®ä¿å§‹ç»ˆå­˜åœ¨`Human-in-the-loop`çš„ç›‘ç£æœºåˆ¶,èƒ½å¤Ÿä»¥ç¡®å®šæ€§çš„æ–¹å¼ç¡®ä¿é«˜é£é™©å‡½æ•°è°ƒç”¨å¿…é¡»ç»è¿‡äººå·¥å®¡æ ¸,åŒæ—¶ä¹Ÿèƒ½å¤Ÿè·å–äººç±»ä¸“å®¶åé¦ˆï¼Œä»è€Œæå‡ AI ç³»ç»Ÿçš„å¯é æ€§å’Œå®‰å…¨æ€§ï¼Œå‡å°‘ LLM å¹»è§‰å¯¼è‡´çš„é£é™©ã€‚

<div align="center">
	<img height=420 src="http://cdn.oyster-iot.cloud/202505210943862.png"><br>
    <b face="é›…é»‘"> The Outer-Loop and Inversion of Control</b>
</div>
<br>

é€šè¿‡`GoHumanloop`çš„å°è£…å¯ä»¥å¸®åŠ©ä½ åœ¨è¯·æ±‚å·¥å…·ã€Agent èŠ‚ç‚¹ã€MCP æœåŠ¡å’Œå…¶å®ƒ Agent æ—¶ï¼Œå®ç°å®‰å…¨é«˜æ•ˆçš„`Human-in-the-loop`ã€‚

## ğŸ“š Key Features

<div align="center">
	<img height=360 src="http://cdn.oyster-iot.cloud/202505291027894.png"><br>
    <b face="é›…é»‘"> GoHumanLoop Architecture</b>
</div>
<br>

`GoHumanloop` æä¾›äº†å¯¹å¤–æä¾›ä»¥ä¸‹æ ¸å¿ƒèƒ½åŠ›ï¼š

- **Approval:** åœ¨æ‰§è¡Œç‰¹å®šå·¥å…·è°ƒç”¨æˆ– Agent èŠ‚ç‚¹æ—¶ï¼Œè¯·æ±‚äººå·¥å®¡æ ¸æˆ–æ‰¹å‡†
- **Information:** åœ¨æ‰§è¡Œä»»åŠ¡æ—¶ï¼Œè·å–äººç±»å…³é”®ä¿¡æ¯ï¼Œå‡å°‘ LLM å¹»è§‰é£é™©
- **Conversation:** é€šè¿‡å¯¹è¯å½¢å¼ä¸äººç±»è¿›è¡Œå¤šè½®äº¤äº’ï¼Œè·å–æ›´ä¸°å¯Œçš„ä¸Šä¸‹æ–‡ä¿¡æ¯
- **Specific:** é’ˆå¯¹ç‰¹å®š Agent æ¡†æ¶ï¼Œæä¾›ç‰¹å®šçš„é›†æˆæ–¹å¼ï¼Œå¦‚`LangGraph`çš„`interrupt`å’Œ`resume`

## ğŸ“… Roadmap

| Feature           | Status     |
| ----------------- | ---------- |
| Approval          | âš™ï¸ Beta    |
| Information       | âš™ï¸ Beta    |
| Conversation      | âš™ï¸ Beta    |
| Email Provider    | âš™ï¸ Beta    |
| Terminal Provider | âš™ï¸ Beta    |
| API Provider      | âš™ï¸ Beta    |
| Default Manager   | âš™ï¸ Beta    |
| GLH Manager       | ğŸ—“ï¸ Planned |
| Langchain Support | âš™ï¸ Beta    |
| CrewAI Support    | ğŸ—“ï¸ Planned |

- ğŸ’¡ GLH Manager - GoHumanLoop Manager å°†å¯¹æ¥æ­£åœ¨æ‰“é€ çš„é›†æˆå¹³å° GoHumanLoop Hubï¼Œä¸ºç”¨æˆ·æä¾›æ›´çµæ´»çš„ç®¡ç†æ–¹å¼ã€‚

## ğŸ¤ Contributing

GoHumanLoop SDK å’Œæ–‡æ¡£æ˜¯å¼€æºçš„ï¼Œæˆ‘ä»¬æ¬¢è¿ä»¥é—®é¢˜ã€æ–‡æ¡£å’Œ PR ç­‰å½¢å¼åšå‡ºè´¡çŒ®ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…[CONTRIBUTING.md](./CONTRIBUTING.md)

## ğŸ“± Contact

<img height=300 src="http://cdn.oyster-iot.cloud/202505231802103.png"/>

ğŸ‰ å¦‚æœä½ å¯¹æœ¬é¡¹ç›®æ„Ÿå…´è¶£ï¼Œæ¬¢è¿æ‰«ç è”ç³»ä½œè€…äº¤æµ

## ğŸŒŸ Star History

[![Star History Chart](https://api.star-history.com/svg?repos=gohumanloop/gohumanloop&type=Date)](https://www.star-history.com/#gohumanloop/gohumanloop&Date)
